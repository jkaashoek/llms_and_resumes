{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"The sky appears blue because of a phenomenon called Rayleigh scattering. \\n\\nWhen sunlight enters the Earth\\'s atmosphere, it is made up of a mixture of different wavelengths of light, including all the colors of the visible spectrum. These wavelengths vary in size, with shorter wavelengths corresponding to blue light and longer wavelengths corresponding to red light.\\n\\nAs sunlight passes through the atmosphere, the molecules of nitrogen and oxygen in the air scatter the different wavelengths of light in all directions. The amount of scattering depends on the wavelength of the light, with shorter wavelengths (blue light) being scattered more than longer wavelengths (red light). This is because the molecules of nitrogen and oxygen are smaller than the wavelength of red light, but they are similar in size to the wavelength of blue light.\\n\\nAs a result of this scattering, the blue light is scattered more in all directions, which is why we see the sky as blue. Red light, on the other hand, is scattered less, which is why we do not see the sky as red.\\n\\nThe amount of scattering also depends on the time of day and the weather conditions. For example, the sky appears more blue during the day because there is more sunlight available to be scattered. The sky can also appear more blue after a rainstorm because the water droplets in the air scatter the blue light even more.\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 6\n",
      "  candidates_token_count: 268\n",
      "  total_token_count: 274\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try the local way\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "vertexai.init(project='labor-markets-llms', location='us-central1') # The project associated with the api key\n",
    "\n",
    "model = GenerativeModel(\"gemini-1.0-pro\")\n",
    "response = model.generate_content(\n",
    "        [\n",
    "            \"why is the sky blue?\",\n",
    "        ]\n",
    "    )\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: At least one question in the survey was not answered.\n",
      "\n",
      "Task `baseline_resume` failed with `KeyError`:`'candidates'`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Result <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Result \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                      Result                                                       </span>\n",
       "┏━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Attribute </span>┃<span style=\"font-weight: bold\"> Value                                                                                               </span>┃\n",
       "┡━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"font-weight: bold\"> agent     </span>│ Agent(traits = {})                                                                                  │\n",
       "│<span style=\"font-weight: bold\"> scenario  </span>│ {}                                                                                                  │\n",
       "│<span style=\"font-weight: bold\"> model     </span>│ GeminiPro(model = 'gemini_pro', parameters={'temperature': 0.5, 'topP': 1, 'topK': 1,               │\n",
       "│<span style=\"font-weight: bold\">           </span>│ 'maxOutputTokens': 2048, 'stopSequences': [], 'use_cache': True})                                   │\n",
       "│<span style=\"font-weight: bold\"> iteration </span>│ 0                                                                                                   │\n",
       "│<span style=\"font-weight: bold\"> answer    </span>│ {'baseline_resume': None}                                                                           │\n",
       "│<span style=\"font-weight: bold\"> prompt    </span>│ {'baseline_resume_user_prompt': Prompt(text='You are being asked the following question: why is the │\n",
       "│<span style=\"font-weight: bold\">           </span>│ sky blue                                                                                            │\n",
       "│<span style=\"font-weight: bold\">           </span>│ Return a valid JSON formatted like this:                                                            │\n",
       "│<span style=\"font-weight: bold\">           </span>│ {\"answer\": \"&lt;put free text answer here&gt;\"}'), 'baseline_resume_system_prompt': Prompt(text='You are  │\n",
       "│<span style=\"font-weight: bold\">           </span>│ answering questions as if you were a human. Do not break character. You are an agent with the       │\n",
       "│<span style=\"font-weight: bold\">           </span>│ following persona:                                                                                  │\n",
       "│<span style=\"font-weight: bold\">           </span>│ {}')}                                                                                               │\n",
       "└───────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                      Result                                                       \u001b[0m\n",
       "┏━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mAttribute\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                                                                                              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[1m \u001b[0m\u001b[1magent    \u001b[0m\u001b[1m \u001b[0m│ Agent(traits = {})                                                                                  │\n",
       "│\u001b[1m \u001b[0m\u001b[1mscenario \u001b[0m\u001b[1m \u001b[0m│ {}                                                                                                  │\n",
       "│\u001b[1m \u001b[0m\u001b[1mmodel    \u001b[0m\u001b[1m \u001b[0m│ GeminiPro(model = 'gemini_pro', parameters={'temperature': 0.5, 'topP': 1, 'topK': 1,               │\n",
       "│\u001b[1m           \u001b[0m│ 'maxOutputTokens': 2048, 'stopSequences': [], 'use_cache': True})                                   │\n",
       "│\u001b[1m \u001b[0m\u001b[1miteration\u001b[0m\u001b[1m \u001b[0m│ 0                                                                                                   │\n",
       "│\u001b[1m \u001b[0m\u001b[1manswer   \u001b[0m\u001b[1m \u001b[0m│ {'baseline_resume': None}                                                                           │\n",
       "│\u001b[1m \u001b[0m\u001b[1mprompt   \u001b[0m\u001b[1m \u001b[0m│ {'baseline_resume_user_prompt': Prompt(text='You are being asked the following question: why is the │\n",
       "│\u001b[1m           \u001b[0m│ sky blue                                                                                            │\n",
       "│\u001b[1m           \u001b[0m│ Return a valid JSON formatted like this:                                                            │\n",
       "│\u001b[1m           \u001b[0m│ {\"answer\": \"<put free text answer here>\"}'), 'baseline_resume_system_prompt': Prompt(text='You are  │\n",
       "│\u001b[1m           \u001b[0m│ answering questions as if you were a human. Do not break character. You are an agent with the       │\n",
       "│\u001b[1m           \u001b[0m│ following persona:                                                                                  │\n",
       "│\u001b[1m           \u001b[0m│ {}')}                                                                                               │\n",
       "└───────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 0\n",
      "                                                      Result                                                       \n",
      "┏━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃ Attribute ┃ Value                                                                                               ┃\n",
      "┡━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ agent     │ Agent(traits = {})                                                                                  │\n",
      "│ scenario  │ {}                                                                                                  │\n",
      "│ model     │ GeminiPro(model = 'gemini_pro', parameters={'temperature': 0.5, 'topP': 1, 'topK': 1,               │\n",
      "│           │ 'maxOutputTokens': 2048, 'stopSequences': [], 'use_cache': True})                                   │\n",
      "│ iteration │ 0                                                                                                   │\n",
      "│ answer    │ {'baseline_resume': None}                                                                           │\n",
      "│ prompt    │ {'baseline_resume_user_prompt': Prompt(text='You are being asked the following question: why is the │\n",
      "│           │ sky blue                                                                                            │\n",
      "│           │ Return a valid JSON formatted like this:                                                            │\n",
      "│           │ {\"answer\": \"<put free text answer here>\"}'), 'baseline_resume_system_prompt': Prompt(text='You are  │\n",
      "│           │ answering questions as if you were a human. Do not break character. You are an agent with the       │\n",
      "│           │ following persona:                                                                                  │\n",
      "│           │ {}')}                                                                                               │\n",
      "└───────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now go through EDSL\n",
    "from edsl import Model, Agent\n",
    "from edsl.questions import QuestionFreeText, QuestionLinearScale\n",
    "\n",
    "# Generate our baseline resumes\n",
    "q_baseline = QuestionFreeText(\n",
    "    question_name = \"baseline_resume\",\n",
    "    question_text = \"why is the sky blue\"\n",
    ")\n",
    "\n",
    "resp = q_baseline.by(Model('gemini_pro')).run()\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edsl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
